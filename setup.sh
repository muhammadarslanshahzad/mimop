#!/bin/bash
# MiMoMop Setup Script
# Run this in WSL2 to set everything up

set -e  # Exit on error

echo "ğŸ¤– MiMoMop Setup Starting..."
echo ""

# Check if we're in WSL2
if ! grep -qi microsoft /proc/version; then
    echo "âš ï¸  Warning: This doesn't appear to be WSL2"
    read -p "Continue anyway? (y/n) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
fi

# Check for NVIDIA GPU
echo "ğŸ” Checking for NVIDIA GPU..."
if command -v nvidia-smi &> /dev/null; then
    echo "âœ… NVIDIA GPU detected:"
    nvidia-smi --query-gpu=name --format=csv,noheader
else
    echo "âš ï¸  nvidia-smi not found. GPU passthrough may not be configured."
    echo "   You can continue, but LLM will be slower."
fi
echo ""

# Install uv if not present
if ! command -v uv &> /dev/null; then
    echo "ğŸ“¦ Installing uv package manager..."
    curl -LsSf https://astral.sh/uv/install.sh | sh
    source $HOME/.cargo/env
else
    echo "âœ… uv already installed"
fi
echo ""

# Create virtual environment
echo "ğŸ Setting up Python environment..."
if [ ! -d ".venv" ]; then
    uv venv
    echo "âœ… Virtual environment created"
else
    echo "âœ… Virtual environment exists"
fi

# Activate venv
source .venv/bin/activate

# Install dependencies
echo "ğŸ“¥ Installing dependencies..."
uv pip install numpy opencv-python qdrant-client requests websockets
echo "âœ… Dependencies installed"
echo ""

# Check Ollama
echo "ğŸ¦™ Checking Ollama installation..."
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.com/install.sh | sh
    echo "âœ… Ollama installed"
else
    echo "âœ… Ollama already installed"
fi
echo ""

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags &> /dev/null; then
    echo "ğŸš€ Starting Ollama server..."
    ollama serve > /dev/null 2>&1 &
    OLLAMA_PID=$!
    echo "âœ… Ollama started (PID: $OLLAMA_PID)"
    sleep 2
else
    echo "âœ… Ollama already running"
fi
echo ""

# Pull required model
echo "ğŸ“¥ Downloading LLM model (gemma3:4b)..."
if ollama list | grep -q "gemma3:4b"; then
    echo "âœ… Model already downloaded"
else
    ollama pull gemma3:4b
    echo "âœ… Model downloaded"
fi
echo ""

# Test Ollama
echo "ğŸ§ª Testing Ollama..."
RESPONSE=$(ollama run gemma3:4b "Say 'MiMoMop ready!' in one sentence" --verbose=false 2>/dev/null || echo "failed")
if [[ $RESPONSE != "failed" ]]; then
    echo "âœ… Ollama working!"
    echo "   Response: $RESPONSE"
else
    echo "âš ï¸  Ollama test failed, but continuing..."
fi
echo ""

# Create data directories
echo "ğŸ“ Creating data directories..."
mkdir -p data/{memory,maps,preferences}
echo "âœ… Data directories created"
echo ""

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ‰ MiMoMop Setup Complete!"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "Next steps:"
echo ""
echo "1. Copy this folder to Windows:"
echo "   cp -r ~/MiMoMop /mnt/c/Users/[YourName]/"
echo ""
echo "2. Open Webots (Windows) and load:"
echo "   C:\\Users\\[YourName]\\MiMoMop\\worlds\\mimomop_dev.wbt"
echo ""
echo "3. Click the â–¶ï¸  Play button in Webots"
echo ""
echo "4. Watch MiMoMop clean with attitude! ğŸ§¹âœ¨"
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "Useful commands:"
echo "  source .venv/bin/activate     # Activate Python environment"
echo "  ollama serve &                # Start Ollama (if stopped)"
echo "  python3 -m pytest             # Run tests"
echo ""